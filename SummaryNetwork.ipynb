{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from nltk import download\n",
    "download('stopwords')\n",
    "download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-match winning streak</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customers save tax</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, cust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claims are not true: Sonam</td>\n",
       "      <td>Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             headlines  \\\n",
       "0    upGrad learner switches to career in ML & Al with 90% salary hike   \n",
       "1         Delhi techie wins free food from Swiggy for one year on CRED   \n",
       "2     New Zealand end Rohit Sharma-led India's 12-match winning streak   \n",
       "3             Aegon life iTerm insurance plan helps customers save tax   \n",
       "4  Have known Hirani for yrs, what if MeToo claims are not true: Sonam   \n",
       "\n",
       "                                                                                                                                                                                                      text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...  \n",
       "1  Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...  \n",
       "2  New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...  \n",
       "3  With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, cust...  \n",
       "4  Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"News_Summary/news_summary_more.csv\")\n",
    "print(reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCIES = {\n",
    "    \"$\": \"USD\", \"zł\": \"PLN\", \"£\": \"GBP\", \"¥\": \"JPY\", \"฿\": \"THB\", \"₡\": \"CRC\", \"₦\": \"NGN\",\"₩\": \"KRW\",\n",
    "    \"₪\": \"ILS\", \"₫\": \"VND\", \"€\": \"EUR\", \"₱\": \"PHP\", \"₲\": \"PYG\", \"₴\": \"UAH\", \"₹\": \"INR\",}\n",
    "CURRENCY_REGEX = re.compile(\n",
    "    \"({})+\".format(\"|\".join(re.escape(c) for c in CURRENCIES.keys())))\n",
    "\n",
    "EMAIL_REGEX = re.compile(\n",
    "    r\"(?:^|(?<=[^\\w@.)]))([\\w+-](\\.(?!\\.))?)*?[\\w+-]@(?:\\w-?)*?\\w+(\\.([a-z]{2,})){1,3}(?:$|(?=\\b))\",\n",
    "    flags=re.IGNORECASE | re.UNICODE,)\n",
    "\n",
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions =          {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\", \"i've\": \"i have\"}\n",
    "def clean_text(text, remove_stopwords = True):\n",
    "    \n",
    "    text = text.lower()\n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "        \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = EMAIL_REGEX.sub(' ',text)\n",
    "    text = CURRENCY_REGEX.sub(' ',text)\n",
    "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(\" \")])    \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r\"'s\\b\",\"\", text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headlines are complete.\n",
      "Texts are complete.\n"
     ]
    }
   ],
   "source": [
    "cleaned_headlines = []\n",
    "cleaned_text = []\n",
    "\n",
    "for headlines in reviews['headlines']:\n",
    "    cleaned_headlines.append(clean_text(headlines, remove_stopwords=False))\n",
    "print(\"Headlines are complete.\")\n",
    "\n",
    "for text in reviews['text']:\n",
    "    cleaned_text.append(clean_text(text))\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  1\n",
      "upgrad learner switches to career in ml   al with 90  salary hike\n",
      "--------------------------------------------------------------------------------\n",
      "saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped transition data scientist tech mahindra 90 salary hike upgrad online power learning powered 3 lakh careers\n",
      "\n",
      "Review:  2\n",
      "delhi techie wins free food from swiggy for one year on cred\n",
      "--------------------------------------------------------------------------------\n",
      "kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit\n",
      "\n",
      "Review:  3\n",
      "new zealand end rohit sharma led india 12 match winning streak\n",
      "--------------------------------------------------------------------------------\n",
      "new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy 12 consecutive victories dating back march 2018 match witnessed india getting 92 seventh lowest total odi cricket history\n",
      "\n",
      "Review:  4\n",
      "aegon life iterm insurance plan helps customers save tax\n",
      "--------------------------------------------------------------------------------\n",
      "aegon life iterm insurance plan customers enjoy tax benefits premiums paid save â¹46 800^ taxes plan provides life cover age 100 years also customers options insure critical illnesses disability accidental death benefit rider life cover age 80 years\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(\"Review: \",i+1) # You can change it by \"Review\" to \"Headline\"\n",
    "    print(cleaned_headlines[i])\n",
    "    print('-'*80)\n",
    "    print(cleaned_text[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #pip install matplotlib\n",
    "\n",
    "text_word_count = []\n",
    "headlines_word_count = []\n",
    "\n",
    "for i in cleaned_text:\n",
    "    text_word_count.append(len(i.split()))\n",
    "for i in cleaned_headlines:\n",
    "    headlines_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text': text_word_count, 'headlines': headlines_word_count})\n",
    "length_df.hist(bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9979776628286298\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in cleaned_text:\n",
    "    if(len(i.split())<=50):\n",
    "        count += 1\n",
    "print(count/len(cleaned_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped tra...</td>\n",
       "      <td>sostok upgrad learner switches to career in ml   al with 90  salary hike eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rup...</td>\n",
       "      <td>sostok delhi techie wins free food from swiggy for one year on cred eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy 12 consecutive victories dating back m...</td>\n",
       "      <td>sostok new zealand end rohit sharma led india 12 match winning streak eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan customers enjoy tax benefits premiums paid save â¹46 800^ taxes plan provides life cover age 100 years also customers options insure critical illnesses disability ...</td>\n",
       "      <td>sostok aegon life iterm insurance plan helps customers save tax eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speaking sexual harassment allegations rajkumar hirani sonam kapoor said i've known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgmen...</td>\n",
       "      <td>sostok have known hirani for yrs  what if metoo claims are not true  sonam eostok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0  saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped tra...   \n",
       "1  kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rup...   \n",
       "2  new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy 12 consecutive victories dating back m...   \n",
       "3  aegon life iterm insurance plan customers enjoy tax benefits premiums paid save â¹46 800^ taxes plan provides life cover age 100 years also customers options insure critical illnesses disability ...   \n",
       "4  speaking sexual harassment allegations rajkumar hirani sonam kapoor said i've known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgmen...   \n",
       "\n",
       "                                                                           headlines  \n",
       "0    sostok upgrad learner switches to career in ml   al with 90  salary hike eostok  \n",
       "1         sostok delhi techie wins free food from swiggy for one year on cred eostok  \n",
       "2       sostok new zealand end rohit sharma led india 12 match winning streak eostok  \n",
       "3             sostok aegon life iterm insurance plan helps customers save tax eostok  \n",
       "4  sostok have known hirani for yrs  what if metoo claims are not true  sonam eostok  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_headlines_len=15\n",
    "max_text_len=60\n",
    "\n",
    "cleaned_text = np.array(cleaned_text)\n",
    "cleaned_headlines = np.array(cleaned_headlines)\n",
    "\n",
    "short_text=[]\n",
    "short_headlines=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    \n",
    "    if(len(cleaned_headlines[i].split())<=max_headlines_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_headlines.append(cleaned_headlines[i])\n",
    "\n",
    "df=pd.DataFrame({'text':short_text,'headlines':short_headlines})\n",
    "df['headlines'] = df['headlines'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['headlines']),test_size=0.1,random_state=0,shuffle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2abdc1d4c0aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#prepare a tokenizer for reviews on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    223\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                                             self.split)\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(text, filters, lower, split)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "thresh=4\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n",
    "\n",
    "print(x_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 71.0662038184974\n",
      "Total Coverage of rare words: 4.859182769476978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88515, 88515)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "thresh=6\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_headlines_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_headlines_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1\n",
    "\n",
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)\n",
    "\n",
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 240)      8268240     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 60, 512), (N 1542144     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 60, 512), (N 2099200     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 240)    2800800     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 60, 512), (N 2099200     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 512),  1542144     embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 512),  524800      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1024)   0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 11670)  11961750    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 30,838,278\n",
      "Trainable params: 30,838,278\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K \n",
    "\n",
    "latent_dim = 512\n",
    "embedding_dim= 240\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "692/692 [==============================] - 542s 783ms/step - loss: 2.9632 - val_loss: 3.2476\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:], epochs=1,callbacks=[es], batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index\n",
    "\n",
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_headlines_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: rabbit track field competition recently held part hunting exhibition 60 kilometres prague czech republic 100 rabbits took part competition featured various events long jump high jump included flat event \n",
      "Original summary: rabbit track and field competition held in czech republic \n",
      "Predicted summary:  what is the features of the world\n",
      "<class 'numpy.ndarray'>\n",
      "[  343   803    90   314  1420   717  3490   378    10  3541  1412  1018\n",
      "   220   145   343  6737  1862   852  1347   753   381  3803   717  1834\n",
      " 17980  7040  1662  2645   169   113  2637     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n",
      "Review: japan based study revealed 13 earth surface enough toxic hydrocarbons cause mass extinction following asteroid impact 9 km wide asteroid struck mexico peninsula 66 million years ago sending millions tons soot atmosphere cooled planet enough trigger mass extinction 75 species including dinosaurs \n",
      "Original summary: dinosaur killing asteroid had 13 chance of doing so study \n",
      "Predicted summary:  earth could be a planet scientists discover\n",
      "<class 'numpy.ndarray'>\n",
      "[ 5566    17 18774   575     1 11000  1092  5619  3823  1153   328   733\n",
      "  3707   667   196  1772  1877   123   123  7638   398   282    48   207\n",
      "   203    55   119   196  1962  1706   799    10     4     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n",
      "Review: police seized 660 cartons indian made foreign liquor worth â¹70 lakh two trucks bihar vaishali friday one trucks intercepted bridge 540 cartons truck intercepted village 120 cartons four people arrested transportation alcohol since alcohol prohibited bihar \n",
      "Original summary: of illegal liquor worth â¹70 lakh seized in bihar \n",
      "Predicted summary:  police arrest of bihar based on liquor in bihar\n",
      "<class 'numpy.ndarray'>\n",
      "[  668   150  1923  4094   138    34   699   578  1980   497  4423 15996\n",
      "   117   424  2125  1980   867   138   150   170   113   498     1  9689\n",
      "   424   976  4445   150  2794     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n",
      "Review: discussion triple talaq bill lok sabha union minister mukhtar abbas naqvi said bill religion added important instil fear minds still practising triple talaq lok sabha thursday passed bill makes instant triple talaq criminal offence \n",
      "Original summary: triple talaq bill not against any religion union minister \n",
      "Predicted summary:  triple talaq bill is a muslim law minister\n",
      "<class 'numpy.ndarray'>\n",
      "[   29  1486    81  5620 14993     1   582    39   301   400  1951   135\n",
      "   120   224  3574  1742   135   120  3060     4 14993     1    39   194\n",
      " 10798    21   130   733   197  1200    25    64    38     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n",
      "Review: responding criticism changing name sonam kapoor ahuja following wedding anand ahuja sonam kapoor questioned know anand changed name people understand concept feminism need go online look description added sonam said changing surname marriage choice \n",
      "Original summary: how do you know anand has not changed surname post marriage sonam \n",
      "Predicted summary:  sonam kapoor is the new wedding anand sonam\n",
      "<class 'numpy.ndarray'>\n",
      "[   39   718  4894  5017    60   858  1360    47  3479  4733   437   990\n",
      "  1063   365   559  2269  3986    59 13694  3121  5907    38  1360  5017\n",
      "     1  8127  1245   365    86   210   282   400   388 10587   103     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n",
      "Review: ugc directed higher educational institutions across country observe september 29 strike day' ncc units universities asked organise special parade besides holding talk sessions ex servicemen inform students sacrifices defence personnel students also encouraged write letters personnel circular added \n",
      "Original summary: universities to celebrate september 29 as strike day' \n",
      "Predicted summary:  mumbai to get day strike after i day event\n",
      "<class 'numpy.ndarray'>\n",
      "[  810   373   839  1765  1676   392    29    53  3288    50    90     1\n",
      "    53   115    49   813 20757  3230  2306  1433  3708  1434   626 19680\n",
      "    50    46    53    49  1958 15997  1663  2822  1234  3597 30242 15466\n",
      "  9690     4     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n",
      "Review: union minister state jitendra singh sunday said mainstream politicians kashmir dangerous separatist leaders stand taken separatists relatively predictable called mainstream leaders turn separatists convenience â added also slammed selective condemnation human rights violation kashmir centric parties \n",
      "Original summary: kashmir leaders more dangerous than separatists union min \n",
      "Predicted summary:  kashmir will be j k minister on kashmir issue\n",
      "<class 'numpy.ndarray'>\n",
      "[   8  531 2002 1827 2264  528 1514  438  179  648 1144  657  438 2126\n",
      "  528   31    3 1112 1718  114 8042   59 1249 1249  965 4471 2919 1320\n",
      "   87 1414  818 4446 1827 2264    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "\n",
      "\n",
      "Review: oracle named lawsuit alleged executives lied shareholders explained cloud sales growing lawsuit claimed oracle engaged coercion threats sell cloud computing products creating unsustainable model fell apart investors alleged lost money oracle stock plummeted march reporting disappointing results \n",
      "Original summary: oracle accused of defrauding investors on cloud sales growth \n",
      "Predicted summary:  firm sues executive over fraud of accused of harassment\n",
      "<class 'numpy.ndarray'>\n",
      "[  290   234  1788   608   475 14994  1386  1288  2588  2479  5386   108\n",
      "  7356    55   658   247   516   928     7   595   487   563  4692     6\n",
      "    35   108     5  1293   951  2479 14995  3575  4863   373  1828     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "2 root error(s) found.\n  (0) Unimplemented:  Cast string to float is not supported\n\t [[node functional_7/Cast (defined at <ipython-input-24-4c1f81035378>:33) ]]\n  (1) Cancelled:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_139165]\n\nFunction call stack:\npredict_function -> predict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-733d5e4f1a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-4c1f81035378>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Encode the input as state vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Generate empty target sequence of length 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_functional_model_init_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return (len(args) == 2 or\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m       data_handler = data_adapter.DataHandler(\n\u001b[0;32m-> 1599\u001b[0;31m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     self._function_spec = function_lib.FunctionSpec.from_function_and_signature(\n\u001b[0;32m--> 780\u001b[0;31m         self._python_function, self.input_signature)\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   \u001b[0;31m# TODO: Remove this private method after updating all its uses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0mit\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mdouble\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0mdifferent\u001b[0m \u001b[0margument\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mso\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mtraced\u001b[0m \u001b[0magain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \"\"\"\n\u001b[1;32m    816\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_count\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m       \u001b[0;34m\"missed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"primary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arg_relaxed_specs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arg_relaxed\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0;34m\"_garbage_collectors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m   ]\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m       \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mTensors\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mVariables\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mArguments\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfiltered\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0maside\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0mTensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompositeTensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mVariables\u001b[0m \u001b[0mare\u001b[0m \u001b[0mignored\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         \u001b[0mpossible_gradient_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         executing_eagerly)\n\u001b[0;32m-> 1924\u001b[0;31m     \u001b[0mforward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_with_tangents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m       flat_outputs = forward_function.call(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0mexecutor_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_call_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor_type\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m     \u001b[0mexecuting_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: 2 root error(s) found.\n  (0) Unimplemented:  Cast string to float is not supported\n\t [[node functional_7/Cast (defined at <ipython-input-24-4c1f81035378>:33) ]]\n  (1) Cancelled:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_139165]\n\nFunction call stack:\npredict_function -> predict_function\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8):\n",
    "    print(\"Review:\",seq2text(x_val[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_val[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_text_len)))\n",
    "    print(type(x_tr[i]))\n",
    "    print(x_tr[i])\n",
    "    print(\"\\n\")\n",
    "text = \"Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.\"\n",
    "array = text.split(\" \")\n",
    "\n",
    "print(decode_sequence(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: summary_model/model/assets\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"summary_model/model\"\n",
    "model.save(checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
